{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "data = pd.read_csv('/Users/sauce/Desktop/DraftKings/ready_data/DraftKingsCleaned.csv', header = None)\n",
    "\n",
    "# rename columns\n",
    "data = data.rename(columns={0: \"season\", \n",
    "                        1:'game_date',\n",
    "                        2: 'player',\n",
    "                        3: 'team',\n",
    "                        4: 'opponent',\n",
    "                        5: 'venue',\n",
    "                        6: 'minutes',\n",
    "                        7: 'usage_rate',\n",
    "                        8: 'rest',\n",
    "                        9: 'avg_threes',\n",
    "                        10: 'avg_reb',\n",
    "                        11: 'avg_ast',\n",
    "                        12: 'avg_stl',\n",
    "                        13: 'avg_blk',\n",
    "                        14: 'avg_tov',\n",
    "                        15: 'avg_pts',\n",
    "                        16: 'avg_points_vs_opp',\n",
    "                        17: 'team_pace',\n",
    "                        18: 'team_ast',\n",
    "                        19: 'team_tov',\n",
    "                        20: 'team_reb_rate',\n",
    "                        21: 'team_offeff',\n",
    "                        22: 'team_defeff',\n",
    "                        23: 'opp_pace',\n",
    "                        24: 'opp_ast',\n",
    "                        25: 'opp_tov',\n",
    "                        26: 'opp_reb_rate',\n",
    "                        27: 'opp_offeff',\n",
    "                        28: 'opp_defeff',\n",
    "                        29: 'opp_pos_avg',\n",
    "                        30: 'salary',\n",
    "                        31: 'fantasy_points',\n",
    "                       })\n",
    "\n",
    "# Avg 10 data\n",
    "data[\"game_date\"] = pd.to_datetime(data.game_date)\n",
    "data.set_index('game_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "df_rolling = data.groupby(['player']).rolling(10).mean().rename(columns={'season':'season1', 'player':'player1'}).reset_index()\n",
    "data = data.reset_index()\n",
    "df_rolling = df_rolling.drop(columns=['player'])\n",
    "df_rolling = df_rolling.rename(columns = {'season1': 'season', 'player1': 'player'})\n",
    "data = pd.merge(data, df_rolling, on=['player', 'season', 'game_date'], left_index= True , suffixes=['', '_AVG10'])\n",
    "\n",
    "# Avg 3 data\n",
    "data[\"game_date\"] = pd.to_datetime(data.game_date)\n",
    "data.set_index('game_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "df_rolling = data.groupby(['player']).rolling(3).mean().rename(columns={'season':'season1', 'player':'player1'}).reset_index()\n",
    "data = data.reset_index()\n",
    "df_rolling = df_rolling.drop(columns=['player'])\n",
    "df_rolling = df_rolling.rename(columns = {'season1': 'season', 'player1': 'player'})\n",
    "df = pd.merge(data, df_rolling, on=['player', 'season', 'game_date'], left_index= True , suffixes=['', '_AVG3'])\n",
    "\n",
    "# Drop useless features\n",
    "df = df.drop(columns=['team_AVG10','opponent_AVG10','venue_AVG10','rest_AVG10',\n",
    "                      'avg_threes_AVG10','avg_reb_AVG10','avg_ast_AVG10','avg_stl_AVG10',\n",
    "                      'avg_blk_AVG10','avg_tov_AVG10','avg_pts_AVG10','avg_points_vs_opp_AVG10',\n",
    "                      'team_pace_AVG10','team_ast_AVG10','team_tov_AVG10','team_reb_rate_AVG10',\n",
    "                      'team_defeff_AVG10','opp_pace_AVG10','opp_ast_AVG10','opp_tov_AVG10',\n",
    "                      'opp_reb_rate_AVG10','opp_offeff_AVG10','salary_AVG10',\n",
    "                      'team_AVG3', 'opponent_AVG3', 'venue_AVG3','rest_AVG3',\n",
    "                      'avg_threes_AVG3', 'avg_reb_AVG3','avg_ast_AVG3', 'avg_stl_AVG3', \n",
    "                      'avg_blk_AVG3', 'avg_tov_AVG3','avg_pts_AVG3', \n",
    "                      'avg_points_vs_opp_AVG3', 'team_pace_AVG3','team_ast_AVG3', \n",
    "                      'team_tov_AVG3', 'team_reb_rate_AVG3','team_defeff_AVG3', \n",
    "                      'opp_pace_AVG3','opp_ast_AVG3', 'opp_tov_AVG3', 'opp_reb_rate_AVG3',\n",
    "                      'opp_offeff_AVG3', 'opp_pos_avg_AVG3','salary_AVG3',\n",
    "                      'team_AVG10_AVG3','opponent_AVG10_AVG3', 'venue_AVG10_AVG3', \n",
    "                      'minutes_AVG10_AVG3','usage_rate_AVG10_AVG3', 'rest_AVG10_AVG3',\n",
    "                      'avg_threes_AVG10_AVG3', 'avg_reb_AVG10_AVG3',\n",
    "                      'avg_ast_AVG10_AVG3', 'avg_stl_AVG10_AVG3', 'avg_blk_AVG10_AVG3',\n",
    "                      'avg_tov_AVG10_AVG3', 'avg_pts_AVG10_AVG3',\n",
    "                      'avg_points_vs_opp_AVG10_AVG3', 'team_pace_AVG10_AVG3',\n",
    "                      'team_ast_AVG10_AVG3', 'team_tov_AVG10_AVG3',\n",
    "                      'team_reb_rate_AVG10_AVG3', 'team_offeff_AVG10_AVG3',\n",
    "                      'team_defeff_AVG10_AVG3', 'opp_pace_AVG10_AVG3',\n",
    "                      'opp_ast_AVG10_AVG3', 'opp_tov_AVG10_AVG3',\n",
    "                      'opp_reb_rate_AVG10_AVG3', 'opp_offeff_AVG10_AVG3',\n",
    "                      'opp_defeff_AVG10_AVG3', 'opp_pos_avg_AVG10_AVG3',\n",
    "                      'salary_AVG10_AVG3', 'fantasy_points_AVG10_AVG3'])\n",
    "\n",
    "# Fill NAs\n",
    "df['fantasy_points_AVG3'] = df['fantasy_points_AVG3'].fillna(df.groupby(['player', 'season'])['fantasy_points'].transform('mean'))\n",
    "df['opp_defeff_AVG3'] = df['opp_defeff_AVG3'].fillna(df.groupby(['opponent', 'season'])['opp_defeff'].transform('mean'))\n",
    "df['team_offeff_AVG3'] = df['team_offeff_AVG3'].fillna(df.groupby(['team', 'season'])['team_offeff'].transform('mean'))\n",
    "df['usage_rate_AVG3'] = df['usage_rate_AVG3'].fillna(df.groupby(['player', 'season'])['usage_rate'].transform('mean'))\n",
    "df['fantasy_points_AVG10'] = df['fantasy_points_AVG10'].fillna(df.groupby(['player', 'season'])['fantasy_points'].transform('mean'))\n",
    "df['minutes_AVG3'] = df['minutes_AVG3'].fillna(df.groupby(['player', 'season'])['minutes'].transform('mean'))\n",
    "df['opp_pos_avg_AVG10'] = df['opp_pos_avg_AVG10'].fillna(df.groupby(['opponent', 'season'])['opp_pos_avg'].transform('mean'))\n",
    "df['opp_defeff_AVG10'] = df['opp_defeff_AVG10'].fillna(df.groupby(['opponent', 'season'])['opp_defeff'].transform('mean'))\n",
    "df['team_offeff_AVG10'] = df['team_offeff_AVG10'].fillna(df.groupby(['team', 'season'])['team_offeff'].transform('mean'))\n",
    "df['usage_rate_AVG10'] = df['usage_rate_AVG10'].fillna(df.groupby(['player', 'season'])['usage_rate'].transform('mean'))\n",
    "df['minutes_AVG10'] = df['minutes_AVG10'].fillna(df.groupby(['player', 'season'])['minutes'].transform('mean'))\n",
    "\n",
    "# Drop non predictive columns \n",
    "df2 = df.drop(columns=['game_date', 'season', 'player', 'team', 'opponent',\n",
    "                     'minutes', 'usage_rate', 'salary'])\n",
    "# Encode Dummies\n",
    "df2 = pd.get_dummies(df2, columns=['venue', 'rest'], drop_first=True)\n",
    "\n",
    "# Grab Target Variable and remove it from data.\n",
    "y = df2['fantasy_points']\n",
    "X = df2.drop(columns = ['fantasy_points'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((45576, 1)).astype(int), values = X, axis = 1)\n",
    "\n",
    "X_opt = X[:, [1,2,3,4,5,7,8,\n",
    "             13,14,19,20,\n",
    "             21,22,26,27,28,30,\n",
    "             31,32,33,36]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_opt, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "Mregressor2 = LinearRegression(normalize=False)\n",
    "Mregressor2.fit(X_train2, y_train2)\n",
    "\n",
    "lin_pred = Mregressor2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36460 samples, validate on 9116 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 255.5100 - val_loss: 46.5855\n",
      "Epoch 2/50\n",
      " - 2s - loss: 46.0071 - val_loss: 36.3568\n",
      "Epoch 3/50\n",
      " - 2s - loss: 41.4589 - val_loss: 35.2787\n",
      "Epoch 4/50\n",
      " - 2s - loss: 40.4326 - val_loss: 34.5826\n",
      "Epoch 5/50\n",
      " - 2s - loss: 39.7488 - val_loss: 34.6276\n",
      "Epoch 6/50\n",
      " - 2s - loss: 39.4493 - val_loss: 34.5340\n",
      "Epoch 7/50\n",
      " - 2s - loss: 38.8817 - val_loss: 34.6160\n",
      "Epoch 8/50\n",
      " - 2s - loss: 38.9252 - val_loss: 34.2049\n",
      "Epoch 9/50\n",
      " - 3s - loss: 38.7294 - val_loss: 34.3314\n",
      "Epoch 10/50\n",
      " - 2s - loss: 38.8584 - val_loss: 34.2864\n",
      "Epoch 11/50\n",
      " - 2s - loss: 38.6206 - val_loss: 34.3625\n",
      "Epoch 12/50\n",
      " - 2s - loss: 38.4764 - val_loss: 34.2131\n",
      "Epoch 13/50\n",
      " - 2s - loss: 38.6460 - val_loss: 34.2649\n",
      "Epoch 14/50\n",
      " - 2s - loss: 38.5716 - val_loss: 34.3056\n",
      "Epoch 15/50\n",
      " - 2s - loss: 38.2862 - val_loss: 34.4448\n",
      "Epoch 16/50\n",
      " - 2s - loss: 38.1811 - val_loss: 34.2984\n",
      "Epoch 17/50\n",
      " - 2s - loss: 38.0248 - val_loss: 34.2335\n",
      "Epoch 18/50\n",
      " - 2s - loss: 38.0551 - val_loss: 34.3402\n",
      "Epoch 19/50\n",
      " - 2s - loss: 38.0640 - val_loss: 34.3384\n",
      "Epoch 20/50\n",
      " - 2s - loss: 38.1188 - val_loss: 34.2568\n",
      "Epoch 21/50\n",
      " - 2s - loss: 37.9406 - val_loss: 34.1962\n",
      "Epoch 22/50\n",
      " - 2s - loss: 37.7938 - val_loss: 34.2543\n",
      "Epoch 23/50\n",
      " - 2s - loss: 37.7706 - val_loss: 34.3310\n",
      "Epoch 24/50\n",
      " - 2s - loss: 38.0624 - val_loss: 34.1509\n",
      "Epoch 25/50\n",
      " - 2s - loss: 37.7328 - val_loss: 34.2484\n",
      "Epoch 26/50\n",
      " - 2s - loss: 37.9392 - val_loss: 34.1445\n",
      "Epoch 27/50\n",
      " - 2s - loss: 37.7958 - val_loss: 34.0611\n",
      "Epoch 28/50\n",
      " - 2s - loss: 37.8815 - val_loss: 34.7664\n",
      "Epoch 29/50\n",
      " - 2s - loss: 37.8729 - val_loss: 34.0631\n",
      "Epoch 30/50\n",
      " - 2s - loss: 37.6604 - val_loss: 34.1656\n",
      "Epoch 31/50\n",
      " - 2s - loss: 37.7944 - val_loss: 34.3770\n",
      "Epoch 32/50\n",
      " - 2s - loss: 37.7189 - val_loss: 34.0451\n",
      "Epoch 33/50\n",
      " - 2s - loss: 37.4110 - val_loss: 34.2863\n",
      "Epoch 34/50\n",
      " - 2s - loss: 37.3781 - val_loss: 34.3419\n",
      "Epoch 35/50\n",
      " - 2s - loss: 37.6094 - val_loss: 34.0408\n",
      "Epoch 36/50\n",
      " - 2s - loss: 37.6705 - val_loss: 34.1121\n",
      "Epoch 37/50\n",
      " - 2s - loss: 37.7277 - val_loss: 34.1982\n",
      "Epoch 38/50\n",
      " - 2s - loss: 37.7925 - val_loss: 34.0791\n",
      "Epoch 39/50\n",
      " - 2s - loss: 37.7164 - val_loss: 34.0853\n",
      "Epoch 40/50\n",
      " - 2s - loss: 37.6317 - val_loss: 34.0941\n",
      "Epoch 41/50\n",
      " - 2s - loss: 37.4118 - val_loss: 34.0892\n",
      "Epoch 42/50\n",
      " - 2s - loss: 37.4189 - val_loss: 34.2573\n",
      "Epoch 43/50\n",
      " - 2s - loss: 37.4217 - val_loss: 34.0625\n",
      "Epoch 44/50\n",
      " - 2s - loss: 37.4570 - val_loss: 34.2701\n",
      "Epoch 45/50\n",
      " - 3s - loss: 37.5514 - val_loss: 34.0234\n",
      "Epoch 46/50\n",
      " - 2s - loss: 37.5302 - val_loss: 34.0222\n",
      "Epoch 47/50\n",
      " - 2s - loss: 37.4815 - val_loss: 33.9482\n",
      "Epoch 48/50\n",
      " - 2s - loss: 37.1448 - val_loss: 34.0100\n",
      "Epoch 49/50\n",
      " - 2s - loss: 37.4795 - val_loss: 34.4305\n",
      "Epoch 50/50\n",
      " - 2s - loss: 37.6340 - val_loss: 34.1861\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "optimizer=optimizers.SGD(lr=1e-4)\n",
    "\n",
    "\n",
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(41, input_dim=41, kernel_initializer='normal', activation='relu'))\n",
    "model_drop.add(Dropout(0.2))\n",
    "model_drop.add(Dense(20, kernel_initializer='normal', activation='relu')) \n",
    "model_drop.add(Dense(1, kernel_initializer='normal'))\n",
    "model_drop.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "mod_drop = model_drop.fit(X_train, y_train,\n",
    "                         batch_size = 25,\n",
    "                         epochs = 50,\n",
    "                         verbose = 2,\n",
    "                         validation_data=(X_test, y_test))\n",
    "\n",
    "ANN_pred = model_drop.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 500, min_samples_leaf = 3,  random_state = 0, n_jobs = -1, min_samples_split = 2) \n",
    "regressor.fit(X_train, y_train)\n",
    "rf_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnest as nested list\n",
    "ANN_pred_list = ANN_pred.tolist()\n",
    "from itertools import chain\n",
    "ann_pred = list(chain(*ANN_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>lin_rg</th>\n",
       "      <th>rf_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.109913</td>\n",
       "      <td>22.690372</td>\n",
       "      <td>23.735803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.425423</td>\n",
       "      <td>1.838132</td>\n",
       "      <td>3.989539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.296963</td>\n",
       "      <td>29.203776</td>\n",
       "      <td>29.457364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.759995</td>\n",
       "      <td>36.787782</td>\n",
       "      <td>39.593445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.014505</td>\n",
       "      <td>11.532207</td>\n",
       "      <td>9.862923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ANN_pred     lin_rg    rf_pred\n",
       "0  22.109913  22.690372  23.735803\n",
       "1   4.425423   1.838132   3.989539\n",
       "2  28.296963  29.203776  29.457364\n",
       "3  36.759995  36.787782  39.593445\n",
       "4  11.014505  11.532207   9.862923"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe of predictions\n",
    "d = {'lin_rg': lin_pred, 'ANN_pred': ann_pred, 'rf_pred': rf_pred}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>lin_rg</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.109913</td>\n",
       "      <td>22.690372</td>\n",
       "      <td>23.735803</td>\n",
       "      <td>22.845363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.425423</td>\n",
       "      <td>1.838132</td>\n",
       "      <td>3.989539</td>\n",
       "      <td>3.417698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.296963</td>\n",
       "      <td>29.203776</td>\n",
       "      <td>29.457364</td>\n",
       "      <td>28.986034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.759995</td>\n",
       "      <td>36.787782</td>\n",
       "      <td>39.593445</td>\n",
       "      <td>37.713740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.014505</td>\n",
       "      <td>11.532207</td>\n",
       "      <td>9.862923</td>\n",
       "      <td>10.803212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ANN_pred     lin_rg    rf_pred       mean\n",
       "0  22.109913  22.690372  23.735803  22.845363\n",
       "1   4.425423   1.838132   3.989539   3.417698\n",
       "2  28.296963  29.203776  29.457364  28.986034\n",
       "3  36.759995  36.787782  39.593445  37.713740\n",
       "4  11.014505  11.532207   9.862923  10.803212"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of all predictions\n",
    "df['mean'] = df.mean(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Array of mean predictions\n",
    "mean = df['mean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.84536259,  3.4176982 , 28.98603435, ..., 23.99145243,\n",
       "        3.66802872, 27.06220759])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 34.15454641040592\n",
      "R2 Score: 0.8262492399786975\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, mean))\n",
    "print('R2 Score:', metrics.r2_score(y_test, mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 34.15454641040592\n",
      "R2 Score: 0.8262492399786975\n"
     ]
    }
   ],
   "source": [
    "d2 = {'lin_rg': lin_pred, 'ANN_pred': ann_pred}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "df2.head()\n",
    "\n",
    "df2['mean'] = df2.mean(axis=1)\n",
    "mean2 = df['mean'].values\n",
    "\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, mean2))\n",
    "print('R2 Score:', metrics.r2_score(y_test, mean2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
