{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv('/Users/sauce/Desktop/DraftKings/ready_data/DraftKingsCleaned.csv', header = None)\n",
    "\n",
    "# rename columns\n",
    "data = data.rename(columns={0: \"season\", \n",
    "                        1:'game_date',\n",
    "                        2: 'player',\n",
    "                        3: 'team',\n",
    "                        4: 'opponent',\n",
    "                        5: 'venue',\n",
    "                        6: 'minutes',\n",
    "                        7: 'usage_rate',\n",
    "                        8: 'rest',\n",
    "                        9: 'avg_threes',\n",
    "                        10: 'avg_reb',\n",
    "                        11: 'avg_ast',\n",
    "                        12: 'avg_stl',\n",
    "                        13: 'avg_blk',\n",
    "                        14: 'avg_tov',\n",
    "                        15: 'avg_pts',\n",
    "                        16: 'avg_points_vs_opp',\n",
    "                        17: 'team_pace',\n",
    "                        18: 'team_ast',\n",
    "                        19: 'team_tov',\n",
    "                        20: 'team_reb_rate',\n",
    "                        21: 'team_offeff',\n",
    "                        22: 'team_defeff',\n",
    "                        23: 'opp_pace',\n",
    "                        24: 'opp_ast',\n",
    "                        25: 'opp_tov',\n",
    "                        26: 'opp_reb_rate',\n",
    "                        27: 'opp_offeff',\n",
    "                        28: 'opp_defeff',\n",
    "                        29: 'opp_pos_avg',\n",
    "                        30: 'salary',\n",
    "                        31: 'fantasy_points',\n",
    "                       })\n",
    "\n",
    "# Avg 10 data\n",
    "data[\"game_date\"] = pd.to_datetime(data.game_date)\n",
    "data.set_index('game_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "df_rolling = data.groupby(['player']).rolling(10).mean().rename(columns={'season':'season1', 'player':'player1'}).reset_index()\n",
    "data = data.reset_index()\n",
    "df_rolling = df_rolling.drop(columns=['player'])\n",
    "df_rolling = df_rolling.rename(columns = {'season1': 'season', 'player1': 'player'})\n",
    "data = pd.merge(data, df_rolling, on=['player', 'season', 'game_date'], left_index= True , suffixes=['', '_AVG10'])\n",
    "\n",
    "# Avg 3 data\n",
    "data[\"game_date\"] = pd.to_datetime(data.game_date)\n",
    "data.set_index('game_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "df_rolling = data.groupby(['player']).rolling(3).mean().rename(columns={'season':'season1', 'player':'player1'}).reset_index()\n",
    "data = data.reset_index()\n",
    "df_rolling = df_rolling.drop(columns=['player'])\n",
    "df_rolling = df_rolling.rename(columns = {'season1': 'season', 'player1': 'player'})\n",
    "df = pd.merge(data, df_rolling, on=['player', 'season', 'game_date'], left_index= True , suffixes=['', '_AVG3'])\n",
    "\n",
    "# Drop useless features\n",
    "df = df.drop(columns=['team_AVG10','opponent_AVG10','venue_AVG10','rest_AVG10',\n",
    "                      'avg_threes_AVG10','avg_reb_AVG10','avg_ast_AVG10','avg_stl_AVG10',\n",
    "                      'avg_blk_AVG10','avg_tov_AVG10','avg_pts_AVG10','avg_points_vs_opp_AVG10',\n",
    "                      'team_pace_AVG10','team_ast_AVG10','team_tov_AVG10','team_reb_rate_AVG10',\n",
    "                      'team_defeff_AVG10','opp_pace_AVG10','opp_ast_AVG10','opp_tov_AVG10',\n",
    "                      'opp_reb_rate_AVG10','opp_offeff_AVG10','salary_AVG10',\n",
    "                      'team_AVG3', 'opponent_AVG3', 'venue_AVG3','rest_AVG3',\n",
    "                      'avg_threes_AVG3', 'avg_reb_AVG3','avg_ast_AVG3', 'avg_stl_AVG3', \n",
    "                      'avg_blk_AVG3', 'avg_tov_AVG3','avg_pts_AVG3', \n",
    "                      'avg_points_vs_opp_AVG3', 'team_pace_AVG3','team_ast_AVG3', \n",
    "                      'team_tov_AVG3', 'team_reb_rate_AVG3','team_defeff_AVG3', \n",
    "                      'opp_pace_AVG3','opp_ast_AVG3', 'opp_tov_AVG3', 'opp_reb_rate_AVG3',\n",
    "                      'opp_offeff_AVG3', 'opp_pos_avg_AVG3','salary_AVG3',\n",
    "                      'team_AVG10_AVG3','opponent_AVG10_AVG3', 'venue_AVG10_AVG3', \n",
    "                      'minutes_AVG10_AVG3','usage_rate_AVG10_AVG3', 'rest_AVG10_AVG3',\n",
    "                      'avg_threes_AVG10_AVG3', 'avg_reb_AVG10_AVG3',\n",
    "                      'avg_ast_AVG10_AVG3', 'avg_stl_AVG10_AVG3', 'avg_blk_AVG10_AVG3',\n",
    "                      'avg_tov_AVG10_AVG3', 'avg_pts_AVG10_AVG3',\n",
    "                      'avg_points_vs_opp_AVG10_AVG3', 'team_pace_AVG10_AVG3',\n",
    "                      'team_ast_AVG10_AVG3', 'team_tov_AVG10_AVG3',\n",
    "                      'team_reb_rate_AVG10_AVG3', 'team_offeff_AVG10_AVG3',\n",
    "                      'team_defeff_AVG10_AVG3', 'opp_pace_AVG10_AVG3',\n",
    "                      'opp_ast_AVG10_AVG3', 'opp_tov_AVG10_AVG3',\n",
    "                      'opp_reb_rate_AVG10_AVG3', 'opp_offeff_AVG10_AVG3',\n",
    "                      'opp_defeff_AVG10_AVG3', 'opp_pos_avg_AVG10_AVG3',\n",
    "                      'salary_AVG10_AVG3', 'fantasy_points_AVG10_AVG3'])\n",
    "\n",
    "# Fill NAs\n",
    "df['fantasy_points_AVG3'] = df['fantasy_points_AVG3'].fillna(df.groupby(['player', 'season'])['fantasy_points'].transform('mean'))\n",
    "df['opp_defeff_AVG3'] = df['opp_defeff_AVG3'].fillna(df.groupby(['opponent', 'season'])['opp_defeff'].transform('mean'))\n",
    "df['team_offeff_AVG3'] = df['team_offeff_AVG3'].fillna(df.groupby(['team', 'season'])['team_offeff'].transform('mean'))\n",
    "df['usage_rate_AVG3'] = df['usage_rate_AVG3'].fillna(df.groupby(['player', 'season'])['usage_rate'].transform('mean'))\n",
    "df['fantasy_points_AVG10'] = df['fantasy_points_AVG10'].fillna(df.groupby(['player', 'season'])['fantasy_points'].transform('mean'))\n",
    "df['minutes_AVG3'] = df['minutes_AVG3'].fillna(df.groupby(['player', 'season'])['minutes'].transform('mean'))\n",
    "df['opp_pos_avg_AVG10'] = df['opp_pos_avg_AVG10'].fillna(df.groupby(['opponent', 'season'])['opp_pos_avg'].transform('mean'))\n",
    "df['opp_defeff_AVG10'] = df['opp_defeff_AVG10'].fillna(df.groupby(['opponent', 'season'])['opp_defeff'].transform('mean'))\n",
    "df['team_offeff_AVG10'] = df['team_offeff_AVG10'].fillna(df.groupby(['team', 'season'])['team_offeff'].transform('mean'))\n",
    "df['usage_rate_AVG10'] = df['usage_rate_AVG10'].fillna(df.groupby(['player', 'season'])['usage_rate'].transform('mean'))\n",
    "df['minutes_AVG10'] = df['minutes_AVG10'].fillna(df.groupby(['player', 'season'])['minutes'].transform('mean'))\n",
    "\n",
    "# Drop non predictive columns \n",
    "df2 = df.drop(columns=['game_date', 'season', 'player', 'team', 'opponent',\n",
    "                     'minutes', 'usage_rate', 'salary'])\n",
    "# Encode Dummies\n",
    "df2 = pd.get_dummies(df2, columns=['venue', 'rest'], drop_first=True)\n",
    "\n",
    "# Grab Target Variable and remove it from data.\n",
    "y = df2['fantasy_points']\n",
    "X = df2.drop(columns = ['fantasy_points'])\n",
    "\n",
    "# Split data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36460 samples, validate on 9116 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: 235.8520 - val_loss: 45.0131\n",
      "Epoch 2/50\n",
      " - 2s - loss: 45.8417 - val_loss: 37.4952\n",
      "Epoch 3/50\n",
      " - 2s - loss: 42.0458 - val_loss: 36.0996\n",
      "Epoch 4/50\n",
      " - 2s - loss: 40.6410 - val_loss: 34.9295\n",
      "Epoch 5/50\n",
      " - 2s - loss: 39.7816 - val_loss: 36.0577\n",
      "Epoch 6/50\n",
      " - 2s - loss: 39.4915 - val_loss: 34.7045\n",
      "Epoch 7/50\n",
      " - 2s - loss: 39.2000 - val_loss: 34.4656\n",
      "Epoch 8/50\n",
      " - 2s - loss: 38.8087 - val_loss: 34.6319\n",
      "Epoch 9/50\n",
      " - 2s - loss: 38.9120 - val_loss: 34.5063\n",
      "Epoch 10/50\n",
      " - 3s - loss: 39.0064 - val_loss: 34.4285\n",
      "Epoch 11/50\n",
      " - 2s - loss: 38.7516 - val_loss: 34.4781\n",
      "Epoch 12/50\n",
      " - 2s - loss: 38.2931 - val_loss: 34.6437\n",
      "Epoch 13/50\n",
      " - 3s - loss: 38.4883 - val_loss: 34.4133\n",
      "Epoch 14/50\n",
      " - 3s - loss: 38.1531 - val_loss: 34.6630\n",
      "Epoch 15/50\n",
      " - 2s - loss: 38.3276 - val_loss: 34.4248\n",
      "Epoch 16/50\n",
      " - 2s - loss: 38.5776 - val_loss: 35.1274\n",
      "Epoch 17/50\n",
      " - 2s - loss: 38.2445 - val_loss: 34.4666\n",
      "Epoch 18/50\n",
      " - 2s - loss: 38.1370 - val_loss: 34.3101\n",
      "Epoch 19/50\n",
      " - 2s - loss: 38.1453 - val_loss: 34.5746\n",
      "Epoch 20/50\n",
      " - 2s - loss: 38.1997 - val_loss: 34.3964\n",
      "Epoch 21/50\n",
      " - 2s - loss: 38.0987 - val_loss: 34.3620\n",
      "Epoch 22/50\n",
      " - 2s - loss: 37.9085 - val_loss: 34.6005\n",
      "Epoch 23/50\n",
      " - 2s - loss: 38.1129 - val_loss: 34.5308\n",
      "Epoch 24/50\n",
      " - 2s - loss: 38.2065 - val_loss: 34.5422\n",
      "Epoch 25/50\n",
      " - 2s - loss: 38.1212 - val_loss: 34.1554\n",
      "Epoch 26/50\n",
      " - 2s - loss: 38.1598 - val_loss: 34.3771\n",
      "Epoch 27/50\n",
      " - 2s - loss: 37.9226 - val_loss: 34.3591\n",
      "Epoch 28/50\n",
      " - 2s - loss: 38.0867 - val_loss: 34.3554\n",
      "Epoch 29/50\n",
      " - 2s - loss: 37.7192 - val_loss: 34.2017\n",
      "Epoch 30/50\n",
      " - 2s - loss: 37.7507 - val_loss: 34.7897\n",
      "Epoch 31/50\n",
      " - 2s - loss: 37.8936 - val_loss: 34.3164\n",
      "Epoch 32/50\n",
      " - 2s - loss: 38.1625 - val_loss: 34.1888\n",
      "Epoch 33/50\n",
      " - 2s - loss: 37.8935 - val_loss: 34.1434\n",
      "Epoch 34/50\n",
      " - 2s - loss: 37.9823 - val_loss: 34.2957\n",
      "Epoch 35/50\n",
      " - 2s - loss: 37.7196 - val_loss: 34.3758\n",
      "Epoch 36/50\n",
      " - 2s - loss: 37.6950 - val_loss: 34.6296\n",
      "Epoch 37/50\n",
      " - 2s - loss: 37.5753 - val_loss: 34.0638\n",
      "Epoch 38/50\n",
      " - 3s - loss: 37.6263 - val_loss: 34.7601\n",
      "Epoch 39/50\n",
      " - 3s - loss: 37.8140 - val_loss: 34.1128\n",
      "Epoch 40/50\n",
      " - 3s - loss: 37.8646 - val_loss: 34.3981\n",
      "Epoch 41/50\n",
      " - 2s - loss: 37.7246 - val_loss: 34.1851\n",
      "Epoch 42/50\n",
      " - 3s - loss: 37.7273 - val_loss: 34.2407\n",
      "Epoch 43/50\n",
      " - 2s - loss: 37.9289 - val_loss: 34.1655\n",
      "Epoch 44/50\n",
      " - 3s - loss: 37.8926 - val_loss: 34.4115\n",
      "Epoch 45/50\n",
      " - 3s - loss: 37.6909 - val_loss: 34.1900\n",
      "Epoch 46/50\n",
      " - 2s - loss: 37.6192 - val_loss: 34.2592\n",
      "Epoch 47/50\n",
      " - 2s - loss: 37.7508 - val_loss: 34.0711\n",
      "Epoch 48/50\n",
      " - 3s - loss: 37.7611 - val_loss: 34.5376\n",
      "Epoch 49/50\n",
      " - 2s - loss: 37.7090 - val_loss: 34.1913\n",
      "Epoch 50/50\n",
      " - 3s - loss: 37.6440 - val_loss: 34.3185\n",
      "Drop Mean Squared Error: 34.31845135303529\n",
      "R2 Score: 0.8254154239469781\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "optimizer=optimizers.SGD(lr=1e-4)\n",
    "\n",
    "\n",
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(41, input_dim=41, kernel_initializer='normal', activation='relu'))\n",
    "model_drop.add(Dropout(0.2))\n",
    "model_drop.add(Dense(20, kernel_initializer='normal', activation='relu')) \n",
    "model_drop.add(Dense(1, kernel_initializer='normal'))\n",
    "model_drop.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "mod_drop = model_drop.fit(X_train, y_train,\n",
    "                         batch_size = 25,\n",
    "                         epochs = 50,\n",
    "                         verbose = 2,\n",
    "                         validation_data=(X_test, y_test))\n",
    "\n",
    "drop_pred = model_drop.predict(X_test)\n",
    "print('Drop Mean Squared Error:', metrics.mean_squared_error(y_test, drop_pred))\n",
    "print('R2 Score:', metrics.r2_score(y_test, drop_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.030643 ],\n",
       "       [ 4.3028283],\n",
       "       [29.00688  ],\n",
       "       ...,\n",
       "       [23.74038  ],\n",
       "       [ 4.30342  ],\n",
       "       [25.878086 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
